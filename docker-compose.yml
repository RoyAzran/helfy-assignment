version: '3.8'

services:
  client:
    build: ./client
    ports:
      - "80:80"
    depends_on:
      - api
    networks:
      - app-network

  api:
    build: ./api
    ports:
      - "3000:3000"
    env_file:
      - ./api/.env
    depends_on:
      kafka:
        condition: service_started
    networks:
      - app-network

  consumer:
    build: ./consumer
    environment:
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - kafka
    networks:
      - app-network

  # TiDB Cluster Components
  pd:
    image: pingcap/pd:latest
    ports:
      - "2379:2379"
    command:
      - --name=pd
      - --client-urls=http://0.0.0.0:2379
      - --peer-urls=http://0.0.0.0:2380
      - --advertise-client-urls=http://pd:2379
      - --advertise-peer-urls=http://pd:2380
      - --initial-cluster=pd=http://pd:2380
      - --data-dir=/data/pd
    volumes:
      - pd_data:/data
    networks:
      - app-network

  tikv:
    image: pingcap/tikv:latest
    command:
      - --addr=0.0.0.0:20160
      - --advertise-addr=tikv:20160
      - --pd=pd:2379
      - --data-dir=/data/tikv
    volumes:
      - tikv_data:/data
    depends_on:
      - pd
    networks:
      - app-network

  tidb:
    image: pingcap/tidb:latest
    ports:
      - "4000:4000"
      - "10080:10080"
    command:
      - --store=tikv
      - --path=pd:2379
      - --advertise-address=tidb
    depends_on:
      - tikv
    networks:
      - app-network

  # TiCDC for Change Data Capture
  ticdc:
    image: pingcap/ticdc:latest
    ports:
      - "8300:8300"
    command:
      - /cdc
      - server
      - --pd=http://pd:2379
      - --addr=0.0.0.0:8300
      - --advertise-addr=ticdc:8300
      - --log-file=""
      - --log-level=info
      - --data-dir=/data/ticdc
    volumes:
      - ticdc_data:/data
    depends_on:
      - pd
      - tikv
      - tidb
    networks:
      - app-network

  # Initialize CDC changefeed to capture database changes
  cdc-init:
    image: pingcap/ticdc:latest
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for TiCDC to be ready..."
        sleep 45
        echo "Creating changefeed..."
        /cdc cli changefeed create \
          --pd=http://pd:2379 \
          --sink-uri="kafka://kafka:9092/tidb-cdc-events?protocol=canal-json&kafka-version=2.4.0" \
          --changefeed-id="db-monitor" \
          --config=/dev/stdin <<EOF
        [filter]
        rules = ['test.*']
        EOF
        echo "Changefeed created successfully"
    depends_on:
      - ticdc
      - kafka
      - db-init
    networks:
      - app-network

  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    networks:
      - app-network

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "user-events:1:1,tidb-cdc-events:1:1"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    depends_on:
      - zookeeper
    networks:
      - app-network

  db-init:
    image: mysql:5.7
    volumes:
      - ./db:/db
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        echo "Waiting for TiDB to be ready..."
        sleep 30
        until mysql -h tidb -P 4000 -u root -e "SELECT 1" 2>/dev/null; do
          echo "TiDB not ready, waiting..."
          sleep 5
        done
        echo "TiDB is ready, initializing database..."
        mysql -h tidb -P 4000 -u root < /db/schema.sql
        echo "Database initialized successfully"
    depends_on:
      - tidb
    networks:
      - app-network

volumes:
  pd_data:
  tikv_data:
  ticdc_data:

networks:
  app-network:
    driver: bridge
